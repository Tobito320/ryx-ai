#!/bin/bash
# Ryx AI V2 - Model Installation Script
# Installs and verifies all required AI models

set -e

echo "ü§ñ Ryx AI V2 - Model Installation"
echo "================================="
echo ""

# Check Ollama
if ! command -v ollama &> /dev/null; then
    echo "‚ùå Ollama not installed"
    echo "Install with: curl -fsSL https://ollama.com/install.sh | sh"
    exit 1
fi

echo "‚úÖ Ollama found"
echo ""

# Check if Ollama is running
if ! ollama list &> /dev/null; then
    echo "‚ö†Ô∏è  Ollama service not running"
    echo "Starting Ollama..."
    ollama serve &
    sleep 3
fi

# Model tiers for V2
declare -A models=(
    ["qwen2.5:1.5b"]="Tier 1 - Ultra Fast (Always Loaded)"
    ["deepseek-coder:6.7b"]="Tier 2 - Balanced (On-Demand)"
    ["qwen2.5-coder:14b"]="Tier 3 - Powerful (Rare Use)"
)

# Check and install models
for model in "${!models[@]}"; do
    description="${models[$model]}"
    echo "üì¶ Checking $model - $description"

    if ollama list | grep -q "^$model"; then
        echo "   ‚úÖ Already installed"
    else
        echo "   üì• Installing $model..."
        if ollama pull "$model"; then
            echo "   ‚úÖ Installation successful"
        else
            echo "   ‚ùå Installation failed"
            exit 1
        fi
    fi
    echo ""
done

# Test each model
echo "üß™ Testing Models"
echo "================="
echo ""

for model in "${!models[@]}"; do
    echo "Testing $model..."

    if echo "test" | ollama run "$model" &> /dev/null; then
        echo "‚úÖ $model works"
    else
        echo "‚ùå $model failed"
        exit 1
    fi
done

echo ""
echo "‚úÖ All models installed and tested successfully!"
echo ""
echo "Model Configuration:"
echo "  - Tier 1 (qwen2.5:1.5b): ~1.5GB VRAM, 50ms latency"
echo "  - Tier 2 (deepseek-coder:6.7b): ~4GB VRAM, 500ms latency"
echo "  - Tier 3 (qwen2.5-coder:14b): ~9GB VRAM, 2000ms latency"
echo ""
echo "üöÄ Ready to use Ryx AI V2!"
