{
  "backend": "ollama",
  "ollama_base_url": "http://localhost:11434",
  "searxng_url": "http://localhost:8888",
  
  "_comment": "Models installed: qwen2.5-coder:14b, qwen2.5-coder:7b, dolphin-mistral:7b, dolphin-phi, qwen2.5:1.5b, qwen2.5:3b, qwen2.5:14b, phi4",
  
  "models": {
    "fast": {
      "name": "qwen2.5:1.5b",
      "role": "fast",
      "description": "1.5B Ultra-Fast - Intent detection, RyxSurf AI",
      "vram_mb": 1000,
      "max_tokens": 2048,
      "num_ctx": 8192,
      "timeout_seconds": 10
    },
    "chat": {
      "name": "qwen2.5-coder:14b",
      "role": "chat",
      "description": "12B Chat - 128K native context, good reasoning",
      "vram_mb": 8000,
      "max_tokens": 4096,
      "num_ctx": 16384,
      "timeout_seconds": 60
    },
    "uncensored": {
      "name": "dolphin-phi",
      "role": "uncensored",
      "description": "2.7B Uncensored - Small, fast, no restrictions",
      "vram_mb": 2000,
      "max_tokens": 4096,
      "num_ctx": 16384,
      "timeout_seconds": 30
    },
    "uncensored_large": {
      "name": "dolphin-mistral:7b",
      "role": "uncensored_large",
      "description": "7B Uncensored - More capable, no restrictions",
      "vram_mb": 5000,
      "max_tokens": 4096,
      "num_ctx": 16384,
      "timeout_seconds": 45
    },
    "code": {
      "name": "qwen2.5-coder:14b",
      "role": "code",
      "description": "14B Coder - Main coding model, HumanEval 88%",
      "vram_mb": 10000,
      "max_tokens": 8192,
      "num_ctx": 16384,
      "num_gpu": 99,
      "num_thread": 12,
      "timeout_seconds": 120
    },
    "code_fast": {
      "name": "qwen2.5-coder:7b",
      "role": "code_fast",
      "description": "7B Coder - Faster coding for simple tasks",
      "vram_mb": 5000,
      "max_tokens": 8192,
      "num_ctx": 16384,
      "timeout_seconds": 60
    },
    "default": {
      "name": "qwen2.5-coder:14b",
      "role": "default",
      "description": "Default to 14B coder for best results",
      "vram_mb": 10000,
      "max_tokens": 8192,
      "num_ctx": 16384,
      "timeout_seconds": 120
    }
  },
  
  "ollama_options": {
    "_comment": "GPU optimization for RX 7800 XT 16GB",
    "num_gpu": 99,
    "num_thread": 12,
    "num_ctx": 16384,
    "use_mmap": true,
    "use_mlock": false
  },
  
  "task_routing": {
    "intent_detection": "fast",
    "simple_chat": "chat",
    "uncensored_chat": "uncensored",
    "search": "chat",
    "code_explore": "code",
    "code_plan": "code",
    "code_apply": "code",
    "code_verify": "code_fast",
    "ryxsurf_ai": "fast",
    "ryxhub_chat": "chat"
  },
  
  "phase_routing": {
    "explore": "code",
    "plan": "code",
    "apply": "code",
    "verify": "code_fast"
  },
  
  "module_defaults": {
    "ryx_cli": "code",
    "ryxhub": "chat",
    "ryxsurf": "fast"
  }
}
