#!/bin/bash
# Ryx AI - Main executable
# Usage: ryx [prompt] or just ryx for interactive session

PROJECT_ROOT="/home/tobi/ryx-ai"
VLLM_CONTAINER="ryx-vllm"
SEARXNG_CONTAINER="ryx-searxng"

# Colors
RED='\033[0;31m'
GREEN='\033[0;32m'
YELLOW='\033[1;33m'
NC='\033[0m'

# Check if Docker is running
check_docker() {
    if ! docker info &>/dev/null; then
        echo -e "${RED}Docker not running. Start with: sudo systemctl start docker${NC}"
        exit 1
    fi
}

# Start vLLM container
start_vllm() {
    if docker ps --format '{{.Names}}' | grep -q "^${VLLM_CONTAINER}$"; then
        # Check if API responds
        if curl -s http://localhost:8001/v1/models &>/dev/null; then
            return 0  # Already running and ready
        fi
    fi
    
    echo -e "${YELLOW}Starting vLLM...${NC}"
    
    # Stop if exists but not running
    docker rm -f "$VLLM_CONTAINER" 2>/dev/null
    
    docker run -d \
        --name "$VLLM_CONTAINER" \
        --device /dev/kfd \
        --device /dev/dri \
        --group-add video \
        --group-add render \
        --ipc=host \
        -v /home/tobi/vllm-models:/models:ro \
        -p 8001:8000 \
        --restart unless-stopped \
        rocm/vllm:rocm6.4.1_vllm_0.9.1_20250702 \
        python3 -m vllm.entrypoints.openai.api_server \
        --model /models/medium/general/qwen2.5-7b-gptq \
        --quantization gptq \
        --max-model-len 8192 \
        --gpu-memory-utilization 0.7 \
        --host 0.0.0.0 \
        &>/dev/null
    
    # Wait for ready (model compilation takes ~60s first time)
    echo -n "Waiting for vLLM"
    for i in {1..90}; do
        if curl -s http://localhost:8001/v1/models &>/dev/null; then
            echo -e " ${GREEN}ready${NC}"
            return 0
        fi
        echo -n "."
        sleep 2
    done
    echo -e " ${RED}timeout${NC}"
    return 1
}

# Start SearXNG container
start_searxng() {
    if docker ps --format '{{.Names}}' | grep -q "^${SEARXNG_CONTAINER}$"; then
        return 0
    fi
    
    echo -e "${YELLOW}Starting SearXNG...${NC}"
    docker rm -f "$SEARXNG_CONTAINER" 2>/dev/null
    
    docker run -d \
        --name "$SEARXNG_CONTAINER" \
        -p 8888:8080 \
        --restart unless-stopped \
        searxng/searxng:latest \
        &>/dev/null
    
    sleep 3
    echo -e "${GREEN}SearXNG ready${NC}"
}

# Stop all Ryx services
stop_services() {
    echo -e "${YELLOW}Stopping Ryx services...${NC}"
    docker stop "$VLLM_CONTAINER" "$SEARXNG_CONTAINER" 2>/dev/null
    docker rm "$VLLM_CONTAINER" "$SEARXNG_CONTAINER" 2>/dev/null
    echo -e "${GREEN}Stopped${NC}"
}

# Cleanup old Docker images
cleanup_docker() {
    echo -e "${YELLOW}Cleaning up Docker...${NC}"
    docker system prune -f
    docker image prune -f
    echo -e "${GREEN}Cleaned${NC}"
}

# Show status
show_status() {
    echo "Ryx Services:"
    if docker ps --format '{{.Names}}' | grep -q "^${VLLM_CONTAINER}$"; then
        echo -e "  vLLM:    ${GREEN}running${NC}"
    else
        echo -e "  vLLM:    ${RED}stopped${NC}"
    fi
    if docker ps --format '{{.Names}}' | grep -q "^${SEARXNG_CONTAINER}$"; then
        echo -e "  SearXNG: ${GREEN}running${NC}"
    else
        echo -e "  SearXNG: ${RED}stopped${NC}"
    fi
}

# Handle commands
case "$1" in
    stop)
        stop_services
        exit 0
        ;;
    cleanup)
        cleanup_docker
        exit 0
        ;;
    status)
        show_status
        exit 0
        ;;
    restart)
        stop_services
        sleep 2
        ;;
esac

# Start services
check_docker
start_vllm
start_searxng

# Activate venv if exists
if [ -d "$PROJECT_ROOT/venv" ]; then
    source "$PROJECT_ROOT/venv/bin/activate"
fi

# Run main
cd "$PROJECT_ROOT"
exec python3 ryx_main.py "$@"
